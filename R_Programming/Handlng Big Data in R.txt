Handlng Big Data in R 
For the demonstration purpose we take iris data and make few changes to simulate it as if it is a big data
probably terrabytes of data.  	

# flat file 
load(ff)
irisff <- read.table.ffdf(
	file= "iris.csv",
	FUN = "read.csv")
# with ffdf it doesnt access the data all at once it acts as apointer and access the data peice by peice

class(irisff)
"ffdf"

names(irisff)
# returns the names of all columns in iris 

iriss[1:10,]
#head(irisff) doesnt work bcoz it isnt data farame its a ff format

library(biglm)
model <- biglm(
	formula = Petal.width ~ Petal.Length,
	data = irisff)

summary(model)

# When using the file and not the actual data loaded in memory we need to use the [] for reference
plot(
	x = irisff$Petal.Length[],
	y = irisff$Petal.Widith[],
	main = "Plotting data",
	xlab = "Length",
	ylab = "Width")


# Model parameters
# Y intercept
b <- summary(model)$mat[1,1]

# Slope of the line 
m <- summary(model)$mat[2,1]

#Plotting 
lines(
	x = irisff$Petal.Length[],
	y = x * irisff$Petal.Width + b,
	col = "red",
	lwd = 3)


# Predicting values for unknown values 
nwdata = data.frame(Petal.Length = c(1,3,2,5,3,2,4), Petal.width = c(0,0,0,0,0,0,0))
predict(
	object = model,
	newdata = nwdata)